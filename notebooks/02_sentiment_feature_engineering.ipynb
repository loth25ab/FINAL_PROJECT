{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7a0757",
   "metadata": {},
   "source": [
    "# Sentiment Feature Engineering\n",
    "\n",
    "This notebook focuses on extracting and engineering sentiment features from news headlines. We use a pre-trained FinBERT model to generate daily sentiment scores, then create additional features to capture sentiment trends, reversals, and recent sentiment shocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b51ebb",
   "metadata": {},
   "source": [
    "## 1. Libraries and Model Setup\n",
    "\n",
    "We use HuggingFace's transformers and FinBERT for sentiment inference, along with pandas and numpy for data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29f0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load FinBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6295894",
   "metadata": {},
   "source": [
    "## 2. Headline Sentiment Scoring\n",
    "\n",
    "We use FinBERT to classify each headline as positive, negative, or neutral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c07ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louft\\anaconda3\\envs\\final_project_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load S&P 500 news dataset\n",
    "df = pd.read_csv('../data/sp500_news.csv', parse_dates=['Date'])\n",
    "\n",
    "def get_finbert_sentiment(texts):\n",
    "    tokens = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "    # FinBERT label order: [positive, negative, neutral]\n",
    "    labels = np.array(['positive', 'negative', 'neutral'])\n",
    "    preds = labels[np.argmax(probs, axis=1)]\n",
    "    return preds, probs\n",
    "\n",
    "# Score all headlines\n",
    "batch_size = 32\n",
    "sentiments, scores = [], []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df['Title'].iloc[i:i+batch_size].tolist()\n",
    "    pred, prob = get_finbert_sentiment(batch)\n",
    "    sentiments.extend(pred)\n",
    "    scores.extend(prob)\n",
    "\n",
    "df['sentiment'] = sentiments\n",
    "df[['positive_score','negative_score','neutral_score']] = np.array(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d28363",
   "metadata": {},
   "source": [
    "## 3. Aggregate Sentiment to Daily Level\n",
    "\n",
    "We summarize sentiment by day to build features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae8ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment as numeric for aggregation\n",
    "sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "df['sentiment_num'] = df['sentiment'].map(sentiment_map)\n",
    "\n",
    "daily_sentiment = df.groupby('Date').agg(\n",
    "    n_headlines=('Title', 'count'),\n",
    "    sentiment_mean=('sentiment_num', 'mean'),\n",
    "    sentiment_std=('sentiment_num', 'std'),\n",
    "    positive_share=('sentiment', lambda x: (x == 'positive').mean()),\n",
    "    negative_share=('sentiment', lambda x: (x == 'negative').mean()),\n",
    "    neutral_share=('sentiment', lambda x: (x == 'neutral').mean()),\n",
    "    pos_score_mean=('positive_score', 'mean'),\n",
    "    neg_score_mean=('negative_score', 'mean'),\n",
    ").fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed1875",
   "metadata": {},
   "source": [
    "## 4. Sentiment Trend & Reversal Features\n",
    "\n",
    "Capture short-term changes and sentiment reversals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6de205",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3  # You can try 3, 5, 7 for more features\n",
    "\n",
    "daily_sentiment['sentiment_trend'] = daily_sentiment['sentiment_mean'].rolling(window).mean()\n",
    "daily_sentiment['sentiment_reversal'] = (\n",
    "    daily_sentiment['sentiment_mean'] * daily_sentiment['sentiment_mean'].shift(1) < 0\n",
    ").astype(int)\n",
    "daily_sentiment['sentiment_change'] = daily_sentiment['sentiment_mean'].diff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9024dfc",
   "metadata": {},
   "source": [
    "## 5. Sentiment Features Sanity Check\n",
    "\n",
    "Let’s quickly run a sanity-check on the resulting daily_sentiment.csv to see if the output makes sense given the pipeline we just built.\n",
    "\n",
    "Here’s what you should expect in the file:\n",
    "- **Date**: Each row represents a single day in your chosen horizon.\n",
    "\n",
    "- **n_headlines**: Number of headlines for that day.\n",
    "\n",
    "- **sentiment_mean**: Average sentiment (should be between -1 and 1; negative = bearish, positive = bullish).\n",
    "\n",
    "- **sentiment_std**: Variability of daily sentiment. Tells you if the day’s news was “all of a kind” or mixed.\n",
    "\n",
    "- **positive_share, negative_share, neutral_share**: % of headlines classified as each type.\n",
    "\n",
    "- **pos_score_mean, neg_score_mean**: Average FinBERT confidence scores.\n",
    "\n",
    "- **sentiment_trend**: Rolling average (should smooth the sentiment_mean).\n",
    "\n",
    "- **sentiment_reversal**: 1 if sentiment flipped sign since the last day; 0 otherwise.\n",
    "\n",
    "- **sentiment_change**: The raw difference in sentiment_mean from previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b7ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  n_headlines  sentiment_mean  sentiment_std  positive_share  \\\n",
      "0 2020-01-02            5        0.000000       0.707107        0.200000   \n",
      "1 2020-01-03            9        0.111111       1.054093        0.555556   \n",
      "2 2020-01-06            5        0.200000       1.095445        0.600000   \n",
      "3 2020-01-07            4        0.250000       0.957427        0.500000   \n",
      "4 2020-01-08            6        1.000000       0.000000        1.000000   \n",
      "5 2020-01-09            7        0.142857       0.690066        0.285714   \n",
      "6 2020-01-10            3        0.333333       1.154701        0.666667   \n",
      "7 2020-01-13            4        1.000000       0.000000        1.000000   \n",
      "8 2020-01-14            7        0.142857       1.069045        0.571429   \n",
      "9 2020-01-15            7        0.428571       0.975900        0.714286   \n",
      "\n",
      "   negative_share  neutral_share  pos_score_mean  neg_score_mean  \\\n",
      "0        0.200000       0.600000        0.200092        0.202745   \n",
      "1        0.444444       0.000000        0.627848        0.361053   \n",
      "2        0.400000       0.000000        0.596702        0.400069   \n",
      "3        0.250000       0.250000        0.504293        0.249761   \n",
      "4        0.000000       0.000000        0.997793        0.001428   \n",
      "5        0.142857       0.571429        0.265321        0.140269   \n",
      "6        0.333333       0.000000        0.667073        0.331703   \n",
      "7        0.000000       0.000000        0.991532        0.002452   \n",
      "8        0.428571       0.000000        0.570998        0.428474   \n",
      "9        0.285714       0.000000        0.689557        0.299668   \n",
      "\n",
      "   sentiment_trend  sentiment_reversal  sentiment_change  \n",
      "0              NaN                   0               NaN  \n",
      "1              NaN                   0          0.111111  \n",
      "2         0.103704                   0          0.088889  \n",
      "3         0.187037                   0          0.050000  \n",
      "4         0.483333                   0          0.750000  \n",
      "5         0.464286                   0         -0.857143  \n",
      "6         0.492063                   0          0.190476  \n",
      "7         0.492063                   0          0.666667  \n",
      "8         0.492063                   0         -0.857143  \n",
      "9         0.523810                   0          0.285714  \n",
      "                                Date  n_headlines  sentiment_mean  \\\n",
      "count                           1037  1037.000000     1037.000000   \n",
      "mean   2022-01-30 19:27:49.816779008    10.351013        0.301740   \n",
      "min              2020-01-02 00:00:00     1.000000       -1.000000   \n",
      "25%              2021-01-19 00:00:00     5.000000        0.088235   \n",
      "50%              2022-01-31 00:00:00     8.000000        0.300000   \n",
      "75%              2023-02-10 00:00:00    15.000000        0.500000   \n",
      "max              2024-03-04 00:00:00    55.000000        1.000000   \n",
      "std                              NaN     7.515764        0.366847   \n",
      "\n",
      "       sentiment_std  positive_share  negative_share  neutral_share  \\\n",
      "count    1037.000000     1037.000000     1037.000000    1037.000000   \n",
      "mean        0.775710        0.555152        0.253412       0.191436   \n",
      "min         0.000000        0.000000        0.000000       0.000000   \n",
      "25%         0.696692        0.421053        0.125000       0.000000   \n",
      "50%         0.843274        0.542857        0.250000       0.166667   \n",
      "75%         0.957427        0.666667        0.363636       0.285714   \n",
      "max         1.414214        1.000000        1.000000       1.000000   \n",
      "std         0.292517        0.212305        0.193380       0.174244   \n",
      "\n",
      "       pos_score_mean  neg_score_mean  sentiment_trend  sentiment_reversal  \\\n",
      "count    1.037000e+03    1.037000e+03      1035.000000         1037.000000   \n",
      "mean     5.536343e-01    2.540137e-01         0.302194            0.182257   \n",
      "min      8.306342e-08    8.794314e-08        -0.549874            0.000000   \n",
      "25%      4.296714e-01    1.193735e-01         0.166667            0.000000   \n",
      "50%      5.421012e-01    2.407009e-01         0.310053            0.000000   \n",
      "75%      6.704267e-01    3.656394e-01         0.446699            0.000000   \n",
      "max      9.999989e-01    9.999999e-01         0.888889            1.000000   \n",
      "std      2.022958e-01    1.876784e-01         0.221176            0.386242   \n",
      "\n",
      "       sentiment_change  \n",
      "count       1036.000000  \n",
      "mean           0.000156  \n",
      "min           -2.000000  \n",
      "25%           -0.289583  \n",
      "50%            0.000000  \n",
      "75%            0.285714  \n",
      "max            2.000000  \n",
      "std            0.510383  \n",
      "       sentiment_mean  sentiment_trend  sentiment_change\n",
      "count     1037.000000      1035.000000       1036.000000\n",
      "mean         0.301740         0.302194          0.000156\n",
      "std          0.366847         0.221176          0.510383\n",
      "min         -1.000000        -0.549874         -2.000000\n",
      "25%          0.088235         0.166667         -0.289583\n",
      "50%          0.300000         0.310053          0.000000\n",
      "75%          0.500000         0.446699          0.285714\n",
      "max          1.000000         0.888889          2.000000\n"
     ]
    }
   ],
   "source": [
    "print(daily_sentiment.head(10))\n",
    "print(daily_sentiment.describe())\n",
    "\n",
    "# Spot-check: any negative headline counts?\n",
    "assert (daily_sentiment['n_headlines'] >= 0).all(), \"Some days have negative headline counts!\"\n",
    "\n",
    "# Are sentiment values reasonable?\n",
    "print(daily_sentiment[['sentiment_mean', 'sentiment_trend', 'sentiment_change']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cd509",
   "metadata": {},
   "source": [
    "## 6. Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1836b",
   "metadata": {},
   "source": [
    "The sentiment feature engineering step successfully generated daily sentiment statistics, including rolling trends and reversals. The results are well-distributed, with no missing or constant values. These features are now ready to be merged with price data and used for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbe2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for use in subsequent modeling notebooks.\n",
    "daily_sentiment.to_csv('../data/daily_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
